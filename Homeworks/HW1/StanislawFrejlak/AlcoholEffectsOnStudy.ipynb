{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Presentation of experiment results"
      ],
      "metadata": {
        "id": "yfwPT5CSx28x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset \"Alcohol Effects On Study\" there is given extensive information about students of two Portuguese schools and their final grades in two subjects: maths and Portuguese. I trained a few models that predict the final grades of the students. As instructed in the description of the dataset, I didn't use information about the mid-term grades of the students as this would make the task easy and uninteresting.\n",
        "\n",
        "Two models that I used are Decision Tree Regressor and Linear Regression. At first, I fit them to the whole dataset. However, as a result, they strongly overfitted to the training data. The R Squared score for the Tree Regressor was negative, and for the Linear Regression it was positive but close to 0.\n",
        "\n",
        "The reason is that the dataset is not very big (only 395 entries), and there is a lot of information about each student (30 columns). Some of the information seem not very relevant for the task (e.g. \"going out with friends\" score, or the time needed for travelling to school). I checked that the importance of the nine most important features account only for 66% of the total explanation of data variance. The model didn't focus only on the most important features.\n",
        "\n",
        "Next, I picked columns which seem to contain the most relevant information:\n",
        "\n",
        "*   'studytime' - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
        "*   'failures' - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
        "*   'schoolsup' - extra educational support (binary: yes or no)\n",
        "*   'famsup' - family educational support (binary: yes or no)\n",
        "*   'paid' - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
        "*   'higher' - wants to take higher education (binary: yes or no)\n",
        "*   'Dalc' - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "*   'Walc' - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "*   'absences' - number of school absences (numeric: from 0 to 93)\n",
        "\n",
        "Given only data from these columns, I trained a new Decision Tree Regressor and a new Linear Regression model, both for math grades data and for Portuguese grades data.\n",
        "\n",
        "This time, I put additional constraints on the decision tree to avoid overfitting. Fine-tuning these constraints (maximal depth of the tree and maximal number of features used for each split) was not easy. In the end, the values with which I came up let the model obtain positive R Squared for both the math and the Portuguese data. However, I needed to use different values for each of these datasets which suggests that the models are not robust.\n",
        "\n",
        "Results of the Linear Regression model were also better for the dataset with selected columns. The discrepancy between the R Squared score for training data and test data was not big.\n",
        "\n",
        "In the Tree Regressors for both the math data and the Portuguese data, 'workday alcohol consumption' was one of the most important explanatory features. Below, I present the feature importances which were higher than 0%.\n",
        "\n",
        "Feature importances for Math grades:\n",
        "*   absences: 35%\n",
        "*   failures: 29%\n",
        "*   studytime: 10%\n",
        "*   schoolsup: 9%\n",
        "*   Walc: 6%\n",
        "*   higher: 5%\n",
        "*   Dalc: 4%\n",
        "\n",
        "\n",
        "Feature importances for Portuguese grades:\n",
        "*   failures: 37%\n",
        "*   Dalc: 22%\n",
        "*   higher: 20%\n",
        "*   studytime: 7%\n",
        "*   absences: 7%\n",
        "*   schoolsup: 5%\n",
        "*   famsup: 2%\n",
        "\n",
        "For the math grades, the most important factors are the number of school absences and the number of past class failures. The workday and weekend alcohol consumption combined together account for 10% explanatory power, similar to the weekly study time or the extra educational support.\n",
        "\n",
        "For the Portuguese grades, the most important factor are past class failures, and the second most important is the workday alocohol consumption.\n",
        "\n",
        "Below, I present R squared scores of all the models:\n",
        "For the full math dataset:\n",
        "*   Tree Regressor on training data: 1.00\n",
        "*   Tree Regressor on test data: -0.29\n",
        "*   Linear Regression on training data: 0.29\n",
        "*   Linear Regression on test data: 0.08\n",
        "\n",
        "For the math dataset with selected features:\n",
        "*   Tree Regressor on training data: 0.30\n",
        "*   Tree Regressor on test data: 0.18\n",
        "*   Linear Regression on training data: 0.12\n",
        "*   Linear Regression on test data: 0.12\n",
        "\n",
        "For the Portuguese dataset with selected features:\n",
        "*   Tree Regressor on training data: 0.16\n",
        "*   Tree Regressor on test data: 0.14\n",
        "*   Linear Regression on training data: 0.27\n",
        "*   Linear Regression on test data: 0.21"
      ],
      "metadata": {
        "id": "IpLFsBn_yN-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code with comments"
      ],
      "metadata": {
        "id": "3o07ddYNx-TF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries and data...\n"
      ],
      "metadata": {
        "id": "Kehn8r_htg3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_ThCODbFe2h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pd.set_option('display.max_columns', None)\n",
        "maths_dataset = pd.read_csv('Maths.csv')\n",
        "portuguese_dataset = pd.read_csv('Portuguese.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I preprocess the data in the following way:\n",
        "\n",
        "\n",
        "*   Drop columns containing mid-term grades\n",
        "*   Change columns containing strings into binary data (if there were only two categories - yes/no), or into one-hot encoded data with a new column for each category\n",
        "*   Scale the values in columns containing numbers so that the lowest value is 0 and the biggest is 1\n",
        "\n",
        "I also select the columns which seem to be the most important. The model will be trained twice: once on the full dataset, and once only on the dataset with the selected columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "_gRvRJEwtqi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(old_dataset, drop_g1_g2=True, scale_g3=False):\n",
        "  dataset = old_dataset.copy()\n",
        "  if drop_g1_g2:\n",
        "    dataset.drop(['G1', 'G2'], axis=1, inplace=True)\n",
        "  columns = dataset.columns\n",
        "  for col in columns:\n",
        "    if dataset[col].astype(str).str.isnumeric().all() and (scale_g3 or col != 'G3'):\n",
        "      col_max, col_min = dataset[col].max(), dataset[col].min()\n",
        "      multiplier = 1 / (col_max - col_min)\n",
        "      dataset[col] = multiplier * (dataset[col].astype(np.float64) - col_min)\n",
        "    else:\n",
        "      values = dataset[col].unique()\n",
        "      if len(values) <= 1:\n",
        "        dataset.drop(col, axis=1, inplace=True)\n",
        "      elif len(values) == 2:\n",
        "        val1 = 'yes' if 'yes' in values else values[0]\n",
        "        dataset[col] = np.where(dataset[col] == val1, 1, 0)\n",
        "      else:\n",
        "        dummies = pd.get_dummies(dataset[[col]], prefix=col)\n",
        "        dataset.drop(col, axis=1, inplace=True)\n",
        "        dataset = pd.concat([dataset, dummies], axis=1)\n",
        "  return dataset.drop('G3', axis=1).astype(np.float64), dataset['G3'].astype(np.float64)\n",
        "\n",
        "def keep_selected_columns(old_dataset):\n",
        "  return old_dataset.copy()[['studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'higher', 'Dalc', 'Walc', 'absences']]\n",
        "\n",
        "math_X, math_y = preprocess_dataset(maths_dataset)\n",
        "portuguese_X, portuguese_y = preprocess_dataset(portuguese_dataset)\n",
        "math_small_X = keep_selected_columns(math_X)\n",
        "portuguese_small_X = keep_selected_columns(portuguese_X)"
      ],
      "metadata": {
        "id": "Vya8-Ov2HgkE"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function fitting regressors to given data. It splits data into the train and test sets. Returns R Squared scores for train and test data for each regressor."
      ],
      "metadata": {
        "id": "ZrJl2LXsvjYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate(X, y, regressors):\n",
        "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "  r2s = []\n",
        "  for regressor in regressors:\n",
        "    regressor.fit(X_train, y_train)\n",
        "    pred_test = regressor.predict(X_test)\n",
        "    r2s.append((regressor.score(X_train, y_train), regressor.score(X_test, y_test)))\n",
        "  return r2s"
      ],
      "metadata": {
        "id": "epz5U5u58jrt"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting regressors to the full dataset of math grades. Visible overfitting."
      ],
      "metadata": {
        "id": "n6nYF-N5v_Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_reg = DecisionTreeRegressor(random_state=0)\n",
        "lin_reg = LinearRegression()\n",
        "regressors = (tree_reg, lin_reg)\n",
        "math_r2s = fit_and_evaluate(math_X, math_y, regressors)\n",
        "print('Results of the tree regressor for math grades:')\n",
        "print('R squared score on the train set equal: %.2f' % math_r2s[0][0])\n",
        "print('R squared score on the test set equal: %.2f' % math_r2s[0][1])\n",
        "print('Importances of nine most important features:')\n",
        "sorted_importance_feature_pairs = sorted(zip(tree_reg.feature_importances_, math_X.columns), reverse=True)\n",
        "for importance, feature in sorted_importance_feature_pairs[:9]:\n",
        "  print('%s: %.0f%%' % (feature, 100*importance))\n",
        "sum_of_low_importances = sum(list(list(zip(*sorted_importance_feature_pairs))[0][9:]))\n",
        "print('Sum of importances of features ranked lower than 9th: %.3f\\n' % sum_of_low_importances)\n",
        "\n",
        "print('Results of the linear regressor for math grades:')\n",
        "print('R squared score on the train set equal: %.2f' % math_r2s[1][0])\n",
        "print('R squared score on the test set equal: %.2f' % math_r2s[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWGy4WNacxeJ",
        "outputId": "03832a5a-681e-400b-c53d-351ec179bca7"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of the tree regressor for math grades:\n",
            "R squared score on the train set equal: 1.00\n",
            "R squared score on the test set equal: -0.29\n",
            "Importances of nine most important features:\n",
            "absences: 19%\n",
            "failures: 9%\n",
            "Walc: 7%\n",
            "studytime: 6%\n",
            "age: 6%\n",
            "Fedu: 5%\n",
            "Fjob_other: 5%\n",
            "Mjob_at_home: 4%\n",
            "romantic: 4%\n",
            "Sum of importances of features ranked lower than 9th: 0.332\n",
            "\n",
            "Results of the linear regressor for math grades:\n",
            "R squared score on the train set equal: 0.29\n",
            "R squared score on the test set equal: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting regressors to the dataset of math grades with nine selected columns. I limit the tree regressor by defining the maximal depth of the tree, and the maximal number of features used during each split."
      ],
      "metadata": {
        "id": "njaaQ8RNwH0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_reg = DecisionTreeRegressor(random_state=0, max_depth=4, max_features=4)\n",
        "lin_reg = LinearRegression()\n",
        "regressors = (tree_reg, lin_reg)\n",
        "math_r2s = fit_and_evaluate(math_small_X, math_y, regressors)\n",
        "print('Results of the tree regressor for math grades using only the important columns:')\n",
        "print('R squared score on the train set equal: %.2f' % math_r2s[0][0])\n",
        "print('R squared score on the test set equal: %.2f' % math_r2s[0][1])\n",
        "print('Feature importances:')\n",
        "sorted_importance_feature_pairs = sorted(zip(tree_reg.feature_importances_, math_small_X.columns), reverse=True)\n",
        "for importance, feature in sorted_importance_feature_pairs:\n",
        "  print('%s: %.0f%%' % (feature, 100*importance))\n",
        "\n",
        "print('Results of the linear regressor for math grades:')\n",
        "print('R squared score on the train set equal: %.2f' % math_r2s[1][0])\n",
        "print('R squared score on the test set equal: %.2f' % math_r2s[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX3upAsXq4fq",
        "outputId": "c1316438-ede0-4764-ea4b-5d21330c3c94"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of the tree regressor for math grades using only the important columns:\n",
            "R squared score on the train set equal: 0.30\n",
            "R squared score on the test set equal: 0.18\n",
            "Feature importances:\n",
            "absences: 35%\n",
            "failures: 29%\n",
            "studytime: 10%\n",
            "schoolsup: 9%\n",
            "Walc: 6%\n",
            "higher: 5%\n",
            "Dalc: 4%\n",
            "paid: 0%\n",
            "famsup: 0%\n",
            "Results of the linear regressor for math grades:\n",
            "R squared score on the train set equal: 0.12\n",
            "R squared score on the test set equal: 0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting regressors to the dataset of Portuguese grades with nine selected columns."
      ],
      "metadata": {
        "id": "z277vKDWxx5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_reg = DecisionTreeRegressor(random_state=0, max_depth=3, max_features=3)\n",
        "lin_reg = LinearRegression()\n",
        "regressors = (tree_reg, lin_reg)\n",
        "portuguese_r2s = fit_and_evaluate(portuguese_small_X, portuguese_y, regressors)\n",
        "print('Results of the tree regressor for portuguese grades using only the important columns:')\n",
        "print('R squared score on the train set equal: %.2f' % portuguese_r2s[0][0])\n",
        "print('R squared score on the test set equal: %.2f' % portuguese_r2s[0][1])\n",
        "print('Feature importances:')\n",
        "sorted_importance_feature_pairs = sorted(zip(tree_reg.feature_importances_, portuguese_small_X.columns), reverse=True)\n",
        "for importance, feature in sorted_importance_feature_pairs:\n",
        "  print('%s: %.0f%%' % (feature, 100*importance))\n",
        "\n",
        "print('Results of the linear regressor for portuguese grades:')\n",
        "print('R squared score on the train set equal: %.2f' % portuguese_r2s[1][0])\n",
        "print('R squared score on the test set equal: %.2f' % portuguese_r2s[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxxU8-DHdQ0W",
        "outputId": "05dc2809-232c-4c0b-aa5a-4ab86b23ced7"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of the tree regressor for portuguese grades using only the important columns:\n",
            "R squared score on the train set equal: 0.16\n",
            "R squared score on the test set equal: 0.14\n",
            "Feature importances:\n",
            "failures: 37%\n",
            "Dalc: 22%\n",
            "higher: 20%\n",
            "studytime: 7%\n",
            "absences: 7%\n",
            "schoolsup: 5%\n",
            "famsup: 2%\n",
            "paid: 0%\n",
            "Walc: 0%\n",
            "Results of the linear regressor for portuguese grades:\n",
            "R squared score on the train set equal: 0.27\n",
            "R squared score on the test set equal: 0.21\n"
          ]
        }
      ]
    }
  ]
}
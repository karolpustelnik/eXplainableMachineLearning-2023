{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate the predictions for some selected observations\n",
    "\n",
    "See `appendix.ipynb`.\n",
    "\n",
    "## 2. Then, calculate the decomposition of these predictions with `LIME` using the package of choice, e.g. in Python: `lime`, `dalex`, in R: `iml`, `localModel`.\n",
    "\n",
    "A LIME explanation for a sample observation\n",
    "![](1.png)\n",
    "\n",
    "## 3. Compare LIME for various observations in the dataset. How stable are these explanations? \n",
    "![](2.png)\n",
    "![](3.png)\n",
    "![](4.png)\n",
    "\n",
    "For this model and these observations the model seems mostly stable - no visible variations in variable attributions for similarly-valued observations.\n",
    "\n",
    "## 4. Compare LIME with the explanations obtained using SHAP. What are the main differences between them?\n",
    "![](5.png)\n",
    "![](6.png)\n",
    "\n",
    "SHAP is more black-boxed - I can apply it to any model accepting and returning numerical values and will get an explanation of how this *exact* value of a variable contributes to the overall prediction.\n",
    "\n",
    "LIME, on the other hand, specifies significance of features in the explainable space, which is more problem-specific (can be regions for images, word buckets for NLP or value ranges for arbitrary numerical data) and preserves less information, but presents it in a (potentially) more understandable way. Unlike SHAP, it does require some notion of *closeness* of observations.\n",
    "\n",
    "## 5. Compare LIME between at least two different models. Are there any systematic differences across many observations?\n",
    "\n",
    "Comment: The top plot of any pair represents the `Random Forest` classifier, while the bottom one refers to `Logistic Regression`.\n",
    "\n",
    "### Observation 1\n",
    "![](7.png)\n",
    "![](8.png)\n",
    "\n",
    "### Observation 2\n",
    "![](9.png)\n",
    "![](10.png)\n",
    "\n",
    "### Observation 3\n",
    "![](11.png)\n",
    "![](12.png)\n",
    "\n",
    "### Observation 4\n",
    "![](13.png)\n",
    "![](14.png)\n",
    "\n",
    "### Observation 5\n",
    "![](15.png)\n",
    "![](16.png)\n",
    "\n",
    "Looks like `Random Forest` consistently attributes high positive contribution of negative `work_type_children` to prediction, while `Logistic Regression` attributes a high *negative* contribution of the same observed variable. This could be caused by correlation between `work_type_children` and `age` variables - maybe `Logistic Regression` is trying to outweigh non-linear dependence of prediction on `age` by assigning positive weight to `work_type_children`?\n",
    "\n",
    "Other way of looking at it - it may be a flaw of LIME neighbour generation - it potentially produces invalid observations like `{ age: 60, work_type_children: 1, ... }`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

<!DOCTYPE html>
<html lang="en"><head>
<script src="01_introduction_files/libs/clipboard/clipboard.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/tabby.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/popper.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="01_introduction_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="01_introduction_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="01_introduction_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.0.36">

  <meta name="author" content="Przemysław Biecek">
  <title>Introduction</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="01_introduction_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title">Introduction</h1>
  <p class="subtitle">eXplainable AI</p>
  <p class="author">Przemysław Biecek</p>
  <p class="date">Machine Learning @ MIMUW 2022</p>
</section>

<section class="slide level2">

<p>
<img src="images/aitech.png" width="100%">
</p>
</section>
<section>
<section id="design-principles" class="title-slide slide level1 center">
<h1>Design Principles</h1>

</section>
<section id="how-it-looked-in-the-past" class="slide level2">
<h2>How it looked in the past</h2>
<p>Interpretable Machine Learning 2022: <a href="https://github.com/MI2-Education/InterpretableMachineLearning2022">https://github.com/MI2-Education/InterpretableMachineLearning2022</a></p>
<ul>
<li>Projects related to applications of XAI techniques to the real world problems in collaboration with business partners.</li>
<li>7 lectures + projects + homeworks + presentations</li>
<li>Key focus: projects that lead to chapters in the ebook ‘XAI stories’</li>
</ul>
<p>
<img src="images/xai_stories.png" width="100%">
</p>
<!-- ![prev editions](images/xai_stories.png) -->
<p><strong>Example stories:</strong></p>
<ul>
<li><a href="https://pbiecek.github.io/xai_stories/story-house-sale-prices.html">https://pbiecek.github.io/xai_stories/story-house-sale-prices.html</a></li>
<li><a href="https://pbiecek.github.io/xai_stories_2/story-seasonal-products.html">https://pbiecek.github.io/xai_stories_2/story-seasonal-products.html</a></li>
<li><a href="https://pbiecek.github.io/xai_stories_2/story-bert-in-the-recommendation-system.html">https://pbiecek.github.io/xai_stories_2/story-bert-in-the-recommendation-system.html</a></li>
</ul>
<p><strong>Comments after previous editions:</strong></p>
<ul>
<li>Cooperation with another university is nice, but on our own we would do more</li>
<li>Business applications are cool, but there is a lot of interest in research projects</li>
<li>Systematic work, especially in the first half of the semester is good, and avoids piling up issues at the end of the semester</li>
<li>Emphasis on commenting on the results, focusing on interpretation is very valuable (although time consuming)</li>
<li>It would be great to have more lectures (than 7) in order to discuss techniques specific to certain modalities, such as computer vision and NLP</li>
</ul>
</section>
<section id="key-information-about-this-edition" class="slide level2">
<h2>Key information about this edition</h2>
<p>This year Github: <a href="https://github.com/mim-uw/TrustworthyMachineLearning-2023/blob/main/README.md">https://github.com/mim-uw/TrustworthyMachineLearning-2023/</a></p>
<p>The classes are divided into:</p>
<ul>
<li>7 lecture blocks, where we will discuss various XAI and fairnes techniques, but this is only an outline of a very rich and interesting field</li>
<li>2 blocks with student presentations, the place where we will learn about selected new XAI techniques</li>
<li>6 homeworks, they are related to the application of a selected XAI technique on a selected predictive problem</li>
<li>a written exam, where there will be tasks similar to those we will discuss during homework</li>
<li>we will mainly work on tabular data, although many of presented methods translate to problems in the area of computer vision, NLP, etc.</li>
</ul>
<p>Lecture/exercises/lab</p>
<ul>
<li>Lecture hours are intended for the theory behind explanations but also project presentations (shared by both groups)</li>
<li>Exercises are for discussions about homeworks and projects</li>
</ul>
</section>
<section id="the-agenda" class="slide level2">
<h2>The agenda</h2>
<ul>
<li>2022-10-07 – Introduction</li>
<li>2022-10-14 – Break-Down / SHAP</li>
<li>2022-10-21 – LIME / LORE</li>
<li>2022-10-28 – CP / PDP</li>
<li>2022-11-04 – PROJECT: <strong>First checkpoint</strong> - show your model and initial ideas for explanations!</li>
<li>2022-11-11 – VIP / MCR</li>
<li>2022-11-18 – Fairness</li>
<li>2022-11-25 – Evaluation of explanations</li>
<li>2022-12-02 – PROJECT: <strong>Second checkpoint</strong> - show your explanations and initial ideas for validation!</li>
<li>2022-12-09 – Counterfactual explanations (?)</li>
<li>2022-12-16 – Concept based explanations (?)</li>
<li>2023-01-13 – Student presentations</li>
<li>2023-01-20 – Student presentations</li>
<li>2023-01-27 – PROJECT: <strong>Final presentation</strong> - show your model, explanations and validation!</li>
</ul>
</section>
<section id="teaching-materials" class="slide level2">
<h2>Teaching materials</h2>
<div class="columns">
<div class="column" style="width:67%;">
<p><strong>Literature extending our lectures</strong></p>
<ul>
<li>Explanatory Model Analysis <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a></li>
<li>Fairness and machine learning <a href="https://fairmlbook.org/">https://fairmlbook.org/</a></li>
<li>An Introduction to Machine Learning Interpretability <a href="https://www.oreilly.com/library/view/an-introduction-to/9781492033158/">https://www.oreilly.com/library/view/an-introduction-to/9781492033158/</a></li>
<li>Interpretable Machine Learning. A Guide for Making Black Box Models Explainable <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></li>
<li>The Hitchhiker’s Guide to Responsible Machine Learning <a href="https://github.com/BetaAndBit/RML">https://github.com/BetaAndBit/RML</a></li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/ema.png"></p>
</div>
</div>
</section>
<section id="grading" class="slide level2">
<h2>Grading</h2>
<p>From different activities, you can get from 0 to 100 points.</p>
<p>51 points are needed to pass this course.</p>
<p>There are four key components.</p>
<ul>
<li>Homeworks (0-24) see for example <a href="https://github.com/mim-uw/TrustworthyMachineLearning-2023/tree/main/Homeworks/HW1">Homeworks/HW1</a></li>
<li>Presentations (0-10)</li>
<li>Project (0-36) expect three milestones</li>
<li>Written exam (0-30)</li>
</ul>
<p>Grades:</p>
<ul>
<li>51-60: dst</li>
<li>61-70: dst+</li>
<li>71-80: db</li>
<li>81-90: db+</li>
<li>91-100: bdb</li>
</ul>
</section>
<section id="the-first-homework" class="slide level2">
<h2>The first homework</h2>
<p>Read more at: <a href="https://github.com/mim-uw/TrustworthyMachineLearning-2023/tree/main/Homeworks/HW1">Homeworks/HW1</a></p>
<p>In future homework, you will explain behaviour of predictive models, but in order to do so, you need to first train a few models.</p>
<p><strong>Deadline</strong>: 2022-10-13 (next week) We will discuss results during next classes</p>
<p><strong>Datasets</strong>: Choose one of the following datasets:</p>
<ul>
<li><a href="https://www.kaggle.com/datasets/jillanisofttech/brain-stroke-dataset">Brain Stroke Dataset</a></li>
<li><a href="https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset">Heart Attack Analysis</a></li>
<li><a href="https://www.kaggle.com/datasets/whenamancodes/alcohol-effects-on-study">Alcohol Effects On Study</a></li>
<li><a href="https://www.kaggle.com/datasets/sanjeetsinghnaik/fifa-23-players-dataset">FIFA-23</a></li>
<li><a href="https://www.kaggle.com/datasets/shashwatwork/municipal-waste-management-cost-prediction">Municipal Waste Management</a></li>
</ul>
<div class="cell">
<style type="text/css">
.reveal {
  font-size: 24px;
  line-height: 1.6!important;
}
code {
  font-size: 18px!important;
  line-height: 1.2!important;
}
pre {
  line-height: 1.2!important;
}
</style>
</div>
</section>
<section id="about-us" class="slide level2">
<h2>About us</h2>
<div class="columns">
<div class="column" style="width:67%;">
<p><strong>Przemysław Biecek</strong></p>
<ul>
<li>works at <em>Faculty of Mathematics, Informatics, and Mechanics</em> at University of Warsaw and <em>Faculty of Mathematics and Information Science</em> at Warsaw University of Technology</li>
<li>research interests include Responsible Machine Learning and eXplainable Artificial Intelligence (eXplainable Artificial Intelligence)</li>
<li>worked in R&amp;D teams at large and small corporations such as Samsung, IBM, Netezza, Disney, iQuor</li>
<li>leads the work of the MI2.AI research team, which carries out XAI related research projects under NCN, NCBiR programmes (looking for collaborators)</li>
<li>this is my fifth edition of classes about XAI</li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/przemek8.png"></p>
</div>
</div>
<div class="columns">
<div class="column" style="width:67%;">
<p><strong>Hubert Baniecki</strong></p>
<ul>
<li>PhD student in CS/AI at the University of Warsaw, MI2.AI research lab</li>
<li>Finished 5-year studies in Data Science at Warsaw University of Technology</li>
<li>3+ years of R&amp;D experience in explainable machine learning</li>
<li>4+ research articles published on this topic, most notably the dalex Python package</li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/hbaniecki.jpg"></p>
</div>
</div>
</section>
<section id="class-participants" class="slide level2">
<h2>Class participants</h2>
<p>Let’s get to know each other!</p>
<p><br></p>

<img data-src="images/menti.png" class="r-stretch"></section></section>
<section>
<section id="model-explanations-why-should-we-care" class="title-slide slide level1 center">
<h1>Model explanations – Why should we care?</h1>

</section>
<section id="models-models-more-models" class="slide level2">
<h2>Models, models, more models …</h2>
<ul>
<li>For a long time in the media, data, machine learning and artificial intelligence were uncritically glorified</li>
<li>The dominant narrative was that almost every problem can be solved having enough data</li>
<li>Serious people were making statements like “there is no point in training radiologists, because they will be replaced by AI”</li>
<li>As with other bubbles, anything that is (star)AI(star) raised (unhealthy) attention</li>
<li>The media raced to announce what new problem AI had been solved</li>
</ul>
<p>
<img src="images/XAI_01.png" width="100%">
</p>
</section>
<section id="however-not-every-model-works" class="slide level2">
<h2>… however, not every model works …</h2>
<p>There is tremendous potential in AI, <strong>but</strong>:</p>
<ul>
<li>there is a growing list of examples in which, despite initial bursts of promise, AI systems did not perform as expected</li>
<li>good results on training data did not transfer to real-world data</li>
<li>systems performed in outright idiotic ways, even though they seemed to work very well during training</li>
<li>more and more people began to cooldown this hurra optimism and collect lists of epic failures of AI</li>
<li>at this point we could discuss various examples of spectacular failures of AI for the next two hours</li>
<li>see ,,Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy’’ by Cathy O’Neil for a very nice overview of these problems (audiobook lasts for over 6 hours)</li>
</ul>
<p>Read more at: <a href="https://romanlutz.github.io/ResponsibleAI/">https://romanlutz.github.io/ResponsibleAI/</a></p>
<p>
<img src="images/XAI_03.png" width="100%">
</p>
</section>
<section id="and-sometimes-it-has-serious-consequences" class="slide level2">
<h2>… and sometimes it has serious consequences</h2>
<ul>
<li>Many AI failures fall into the category “ridiculous”. Whether it’s a malfunctioning facial recognition system that takes pictures, or a cleaning robot that can spread some mess all over the room.</li>
<li>But AI systems are also increasingly being used for serious applications in the fields of biology, medicine or finance. And here mistakes in operation can give rise to serious consequences.</li>
<li>In fact, every major company developing AI solutions has such failures on its conscience. The slide above is from a StatNews report on the implementation of IBM Watson for Oncology. Despite enormous resources and even greater hopes, the system was not well received by doctors. Recommendations for this system were called inacurate and unsafe.</li>
</ul>
<p>Read more: <a href="https://www.statnews.com/wp-content/uploads/2018/09/IBMs-Watson-recommended-unsafe-and-incorrect-cancer-treatments-STAT.pdf">https://www.statnews.com/</a></p>
<p>
<img src="images/XAI_06.png" width="100%">
</p>
</section>
<section id="this-should-not-happen" class="slide level2">
<h2>This should not happen</h2>
<ul>
<li>How do we know what the model has learned? Maybe it bases decisions on some strange artifact?</li>
<li>This is not a made up possibility, in the example below the model’s decisions correlated strongly with the fact that there were captions in the lower left corner.</li>
<li>It turns out that in the learning data there was often a description in the lower left corner next to the horse pictures. Instead of learning to recognize the characteristics of horses, it is much easier to recognize the presence of text in the lower left corner.</li>
</ul>
<p>Read more: <a href="https://www.nature.com/articles/s41467-019-08987-4">Unmasking Clever Hans predictors and assessing what machines really learn</a></p>
<p>
</p><center>
<img src="images/CleverHans.png" width="100%">
</center>
<p></p>
</section>
<section id="sometimes-users-differ-on-how-the-system-should-work" class="slide level2">
<h2>Sometimes users differ on how the system should work</h2>
<ul>
<li>Users may have different expectations about how the system should work</li>
<li>For example, a system showing a job ads for truck drivers, presenting these ads more often to men aged 20-50. Is this an example of age and gender discrimination or an increase in the chance of getting an employee?</li>
<li>Who should define who should watch the selected advertisement and when</li>
</ul>
<p>Read more: <a href="https://www.propublica.org/article/facebook-ads-can-still-discriminate-against-women-and-older-workers-despite-a-civil-rights-settlement">https://www.propublica.org</a></p>
<p>
<img src="images/fairness_02.png" width="100%">
</p>
</section>
<section id="number-of-published-articles-on-xai" class="slide level2">
<h2>Number of published articles on XAI</h2>
<ul>
<li>The number of papers related to XAI is growing rapidly</li>
<li>It is not only new methods but also processes, practices, examples of application in various disciplines</li>
</ul>
<p>Read more: <a href="https://www.mdpi.com/2076-3417/12/3/1353">A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks. Applied Sciences 2022</a></p>
<p>
</p><center>
<img src="images/articles.png" width="80%">
</center>
<p></p>
</section>
<section id="the-reaction-is-to-try-to-regulate-ai" class="slide level2">
<h2>The reaction is to try to regulate AI</h2>
<ul>
<li>For several years, the European Commission has been working on a so-called AI Act to regulate the use of automated algorithms within the European Union.</li>
<li>The act is expected to be passed next year – 2023</li>
<li>The act includes specific expectations related to the explainability of decisions supported by automated decision-making systems</li>
</ul>
<p>Read more: <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206">https://eur-lex.europa.eu</a></p>
<p>
<img src="images/XAI_07.png" width="100%">
</p>
</section></section>
<section>
<section id="model-explanations-how-to-get-there" class="title-slide slide level1 center">
<h1>Model explanations – How to get there</h1>

</section>
<section id="darpa-program-for-development-of-xai-methods" class="slide level2">
<h2>DARPA program for development of XAI methods</h2>
<ul>
<li>You may know DARPA for developing computer mouse (1964), GPS (1983), Internet – ARPANet (1969) or drones (1988).</li>
<li>In 2017, DARPA launched a major program to fund projects focused on Explainable Artificial Intelligence (XAI) in particular on AI-human collaboration. Research funded by this program is still ongoing and the program itself has contributed to the growing interest in XAI topics.</li>
<li>It is worth reading about the assumptions and concepts of this program, many of the ideas are still (after 5 years) valid and attractive research topics.</li>
</ul>
<p>Read more: <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">https://www.darpa.mil/</a></p>
<p>
</p><center>
<img src="images/XAI_10.png" width="100%">
</center>
<p></p>
</section>
<section id="responsible-and-ethical-ai---the-business-response" class="slide level2">
<h2>Responsible and ethical AI - the business response</h2>
<ul>
<li>Interestingly, this line of research was very quickly get the interest of business.</li>
<li>On the websites of many companies dealing with AI-related products and services, you can find bookmarks with the topic of “Trustworthy AI”.</li>
<li>On the slide we have a few sites of companies producing software for (Auto)ML, namely H2O, we have consulting companies such as McKinsey, PWC, IBM, as well as product companies such as Samsung and Tensorflow.</li>
<li>Many companies are outdoing themselves in presenting their principals which include slogans such as Transparency, Fairness, Explaianbility. How can these slogans be realized?</li>
</ul>
<p>
</p><center>
<img src="images/XAI_11.png" width="100%">
</center>
<p></p>
</section>
<section id="initiatives-to-increase-the-effectiveness-of-ai-applications-are-being-undertaken-by-various-organizations" class="slide level2">
<h2>Initiatives to increase the effectiveness of AI applications are being undertaken by various organizations</h2>
<ul>
<li>Not only business, but also large international organizations are actively working to promote AI solutions that are safe and transparent</li>
</ul>
<p>
</p><center>
<img src="images/XAI_09.png" width="100%">
</center>
<p></p>
</section>
<section id="the-right-to-an-explanation-in-europe" class="slide level2">
<h2>The right to an explanation in Europe</h2>
<p>From <a href="https://www.privacy-regulation.eu/en/recital-71-GDPR.htm">Recital 71 EU GDPR</a></p>
<p>,,(71) The data subject should have the right not to be subject to a decision, which may include a measure, evaluating personal aspects relating to him or her which is based solely on automated processing and which produces legal effects concerning him or her or similarly significantly affects him or her, such as automatic refusal of an online credit application or e-recruiting practices without any human intervention.</p>
<p>Such processing includes ‘profiling’ that consists of any form of automated processing of personal data evaluating the personal aspects relating to a natural person, in particular to analyse or predict aspects concerning the data subject’s performance at work, economic situation, health, personal preferences or interests, reliability or behaviour, location or movements, where it produces legal effects concerning him or her or similarly significantly affects him or her.</p>
<p>However, decision-making based on such processing, including profiling, should be allowed where expressly authorised by Union or Member State law to which the controller is subject, including for fraud and tax-evasion monitoring and prevention purposes conducted in accordance with the regulations, standards and recommendations of Union institutions or national oversight bodies and to ensure the security and reliability of a service provided by the controller, or necessary for the entering or performance of a contract between the data subject and a controller, or when the data subject has given his or her explicit consent.</p>
<p><strong>In any case, such processing should be subject to suitable safeguards, which should include specific information to the data subject and the right to obtain human intervention, to express his or her point of view, to obtain an explanation of the decision reached after such assessment and to challenge the decision</strong>.’’</p>
</section>
<section id="the-right-to-an-explanation-in-poland" class="slide level2">
<h2>The right to an explanation in Poland</h2>
<ul>
<li>Interestingly, the right of explanation has also been present in Polish law for at least three years.</li>
<li>Financial institutions still have not developed good solutions.</li>
<li>However, the topic of explainability as a consumer right is there, and we see an growing demand for solutions that will realize this need for explainability.</li>
</ul>
<p>
</p><center>
<img src="images/XAI_08.png" width="100%">
</center>
<p></p>
</section></section>
<section>
<section id="model-explanations-what-we-will-talk-about" class="title-slide slide level1 center">
<h1>Model explanations – What we will talk about</h1>

</section>
<section id="how-to-think-about-the-explainability-of-predictive-models" class="slide level2">
<h2>How to think about the explainability of predictive models</h2>
<p>When we think about the interpretability of models we usually distinguish three classes of methods</p>
<ul>
<li><strong>Interpretable by design,</strong> i.e.&nbsp;methods whose structure allows us to directly analyze how the prediction was formed. For different classes of models, explanations may look different, but they are directly based on model parameters. For linear models they are coefficients, for k-neighbors they are neighbors, for naive Bayes they are marginal distributions</li>
<li><strong>model specific,</strong> i.e.&nbsp;methods whose structure is complex but can be summarized or represented to better understand the relationship between input and output. The two most common classes of models with model-specific explanations are tree model committees (here we can summarize the tree structure) and neural networks (here we can usually summarize the flow of the signal through the network)</li>
<li><strong>model agnostic,</strong> i.e.&nbsp;methods to which this course is devoted, methods that assume nothing about the structure of the model and can be used for models with different structures. Moreover, they can be used to compare models with different structures.</li>
</ul>
<p>Read more: <a href="https://arxiv.org/pdf/2009.13248.pdf">arxiv.org/2009.13248</a></p>
<p>
</p><center>
<img src="images/XAI_12.png" width="100%">
</center>
<p></p>
</section>
<section id="there-is-no-one-size-fits-all-solution" class="slide level2">
<h2>There is no one-size-fits-all solution</h2>
<ul>
<li>We will talk about how to identify the needs of different stakeholders and match them with explanatory techniques</li>
<li>It’s still area that needs more active research, there’s a lot of talk about user needs, but the available methods are more aimed at model developers</li>
</ul>
<p>Read more: <a href="https://www.tandfonline.com/doi/abs/10.1080/01605682.2021.1922098">Transparency, Auditability and eXplainability of Machine Learning Models in Credit Scoring</a></p>
<p>
</p><center>
<img src="images/Transparency.png" width="100%">
</center>
<p></p>
</section>
<section id="the-pyramid-of-explainability" class="slide level2">
<h2>The pyramid of explainability</h2>
<ul>
<li>In this class we will discuss several techniques for global and local analysis of the model.</li>
<li>Global analysis is concerned with the behavior of the model on the entire data</li>
<li>Local analysis deals with the model’s behavior on one/some observations</li>
<li>The subsequent techniques are complementary, creating an extended, increasingly detailed description of the model’s behavior</li>
</ul>
<p>
</p><center>
<img src="images/XAI.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-statistics" class="slide level2">
<h2>Shift in our focus: Statistics</h2>
<ul>
<li>Statistical analysis of data most often assumes a great deal of knowledge about the phenomenon. Understanding the data allows to choose appropriate transformations, representations. Verification is oriented toward hypothesis testing, such as by p-values</li>
</ul>
<p>
</p><center>
<img src="images/shift1.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-machine-learning" class="slide level2">
<h2>Shift in our focus: Machine Learning</h2>
<ul>
<li>Machine learning puts a priority on optimizing the model, especially for performance. There is a lot of searching through the space of possible solutions here to find the best one</li>
<li>Knowledge of the phenomenon is no longer so important</li>
</ul>
<p>
</p><center>
<img src="images/shift2.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-human-oriented-ml" class="slide level2">
<h2>Shift in our focus: Human Oriented ML?</h2>
<ul>
<li>What’s next. If model building can be easily and quickly automated, in-depth model verification will become more important</li>
<li>This is where models are created seamlessly according to the needs of the user, and the user can focus on decisions supported by the models</li>
</ul>
<p>
</p><center>
<img src="images/shift3.png" width="100%">
</center>
<p></p>
</section></section>
<section id="take-home-message" class="title-slide slide level1 center">
<h1>Take-home message</h1>
<p><strong>Why interpretability is important?</strong></p>
<ul>
<li>Higher trust -&gt; <strong>higher adoption of ML/AI solutions</strong> that will support decision making process</li>
<li>May be <strong>required by auditors, regulators</strong>, law</li>
<li>New tool for model exploration -&gt; to <strong>gain new insights</strong> about the data/nature of some phenomenom</li>
<li>Gatekeeping role, human can <strong>control and/or block wrong decisions</strong> when knowing key reasons behind these decisions</li>
<li><strong>Debugg/improve data or models</strong>, identify wrong behaviour and help to plan actions to fix it</li>
<li><strong>Deeper diagnostic of models</strong>, validation against some domain knowledge, expectations or other values (like human rights -&gt; fairness)</li>
</ul>
<p><strong>Goals for this course:</strong></p>
<ul>
<li>Learn XAI techniques (model agnostic)</li>
<li>Learn the strengths and weaknesses of these techniques while doing a hands-on projects</li>
<li>Learn how to communicate explanations to (domain) experts and lay users</li>
</ul>

<img src="images/XAI.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>eXplainable AI – Introduction – MIM UW – 2022</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="01_introduction_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="01_introduction_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="01_introduction_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        function fireSlideChanged(previousSlide, currentSlide) {

          // dispatch for htmlwidgets
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for reveal
        if (window.Reveal) {
          window.Reveal.addEventListener("slidechanged", function(event) {
            fireSlideChanged(event.previousSlide, event.currentSlide);
          });
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          let href = ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>